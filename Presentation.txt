Introduction

We are the Informatics Program at UCLA, lead by Douglas Bell, under the CTSI at UCLA. I am the lead application programmer, developing and managing our applications infrastructure. I'm going to present to you our initial prototype of a data-quality and data-infrastructure monitoring tool, which we intend to expand into an easy-to-use, and free-and-open-source system. 

Our system is called DTEQTIV, short for "Dashboard for Technology Evaluation and Quality Testing using Interactive Visualization". We know we stretched our imagination a bit to come up with that name, but what we want to emphasize here is that this tool is your own detective, who will try to help you detect data quality issues and technical-infrastructure related issues.

Why?
This system started out as a bunch of automated query testing scripts, which we would run against our i2b2/shrine infrastructure on our UCReX and LADR networks. These networks allow us to find number of patients at each site, that meet a specific search criteria. We started off by running the same 16-20 queries every 4 hours on this network, to assess stability, and to detect any issues. We then realized that we could use the data that these scripts collected for data quality analysis, by comparing the numbers across sites for each query. That was the first motivation for this project: how do we leverage our existing multi-site networks to do data-quality analysis [TODO: add what types of issues we expect]. The other motivation was: when we detect that some of these issues, how do we "comment on" or "annotate" these issues, so that an end-user looking at these numbers has some context about whether there are any special considerations to take into account while performing analysis. This lead to the idea of building in a "comments sytem" or "metadata annotations" into the system. Another motivation was: if someone wanted to very quickly check the data that we had on our federated networks, how could we build an interface that allowed rapid patient-count checking.

What?
Since DTEQTIV is a system, rather than just a tool, our intention is to make it easy to deploy, easy to add new features, and agnostic to specific underlying data models. For ease of deployment, we have started off with a dockerized version, which pulls all components from github and spins the system up in a few minutes. The data processing scripts are written in Python, which will allow us to write complicated data quality analysis scripts in future. Right now we have added a few processing scripts that do basic data quality issue detection. Also most of the visualization scripts are javascript-based, using d3.js, charts.js etc. We have also decoupled the data layer from any existing system. So DTEQTIV tables can just be loaded using simple csv files, or complicated ETL jobs. 

How [Demo]?

Currently our servers are deployed on the Amazon cloud, our application servers are EC2 and the demo database is on RDS. This is the login screen, and we have a few demo user accounts created here right now. We have also added adapters for connecting with the i2b2 login framework, so that it can just use the i2b2 login mechanism right out of the box. 

This is the landing page. We have 4 tabs that we are currently prototyping, each with a different functionality. We chose the names based on their closest fit to the "detective" theme. We have the "Inspector", "Monitor", "Visualizer" and "Informant". We will go through these tabs one-by-one, but before that i'd like to introduce them quickly. The inspector tab is meant to be the default tab, that shows the ontology-tree that has the ontologies describing the concepts that describe our data. Currently we are using the same ontology that we have in our i2b2 system. The Monitor tab shows us data from our automated network testing queries, and allowing us to monitor the network status more effectively. The Visualizer tab is a place where we would want to add different data visualization charts, that can help users get a sense of the underlying data. Its currently under construction. The Informant tab shows the results of the python data-quality issues detection scripts.

Lets explore the informant tab. Clicking on each of these ontology trees shows the yearly patient count distribution that we have obtained from various sites. This data is precomputed, so it can be accessed very quickly. Also, for each tree item, we have integrated a commenting system, where a user can leave comments. When a user leaves comments, these are visible only to the user, and to the admin, who can choose to make them public for all users to see. 

Moving on to the Monitor tab. This shows the results of our automated query scripts that query the network every 12 hours. Clicking on the rows gives some details about what the counts returned by the networks look like.

On the visualizer tab, we have some visualizations to explain the data better. I will skip this tab for this presentation, as the visualizations are interesting but not complete. 

The Informant tab, we have some sample data for issues detected by the system. We intend to add more scripts to this tab, and also make it easy for anyone to add python data analysis scripts.